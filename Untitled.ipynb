{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "import pandas as pd\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normaliza_arquivos(data, sep):\n",
    "    dataset=[]\n",
    "    for line in data:\n",
    "        values = line.split(sep)\n",
    "        text = ','.join(values[0].split(',')[1:]).lower()\n",
    "        label = values[1].lower()\n",
    "        if len(text) > 1:\n",
    "            if label == 'bom':\n",
    "                label = 'b'\n",
    "            elif label == 'ruim':\n",
    "                label = 'r'\n",
    "            elif label == 'neutro':\n",
    "                label = 'n'\n",
    "            text = text.lower().replace('\"', '').replace(\"'\", \"\")\n",
    "            dataset.append((text, label))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lendo arquivo Fabiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('treinamento/tweets_0_analise.csv', encoding='latin-1') as f:\n",
    "    data0 = f.readlines()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lendo arquivo Carlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('treinamento/tweets_1-PacoteDeMil.csv', encoding='utf-8') as f:\n",
    "    data1 = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('treinamento/tweets_2.csv', encoding='utf-8') as f:\n",
    "    data2 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('√© tanta gente falando te amo sem amar... ü§¶üèΩ\\u200d‚ôÄÔ∏è', 'r'),\n",
       " ('apaguei todo meu album de fotos tiradas pela camera do meu samsung e nao consigo recuperar por nada',\n",
       "  'r'),\n",
       " ('#inarivoltapro@m', 'n'),\n",
       " ('@pabllovittar pls', 'n'),\n",
       " ('a fam√≠lia de voc√™s sabem da vontade de serem doadores de √≥rg√£os? espero que sim, se n√£o, avisem! #doeorgaos #doevidas',\n",
       "  'n'),\n",
       " ('to morrendo de fome e de sono mds üíî', 'r'),\n",
       " ('a felicidade √© uma palavra de dez letras, mas a minha resume-se em quatro: voc√™!',\n",
       "  'b'),\n",
       " ('acho que ja vou dormir', 'b'),\n",
       " ('@sanyanaa @lelemills falei a mesma coisa', 'n'),\n",
       " ('inocente rsrsrs', 'n')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = normaliza_arquivos(data0, ';')\n",
    "dataset += normaliza_arquivos(data1, '\\t')\n",
    "dataset += normaliza_arquivos(data2, '\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_number = int(len(dataset)*0.2)\n",
    "train_number = int(len(dataset)*0.8)\n",
    "\n",
    "test = random.sample(dataset, test_number)\n",
    "train = random.sample(dataset, train_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = NaiveBayesClassifier(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textblob.classifiers.NaiveBayesClassifier"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = 0\n",
    "for i in test:\n",
    "    text = i[0]\n",
    "    res = cl.classify(text)\n",
    "    if res == i[1]:\n",
    "        result+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577\n"
     ]
    }
   ],
   "source": [
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q=cl.prob_classify(\"isso √© muito foda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
